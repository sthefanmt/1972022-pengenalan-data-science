{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3682b3b1-f1b9-4971-a1e6-2ee2ac5a911c",
   "metadata": {},
   "source": [
    "# Bag of Words, Stop Word Filtering & TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ffc7ef-b983-4215-acea-40f799d5fbf4",
   "metadata": {},
   "source": [
    "1972022 - Sthefan Marley Tanza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c0f43d-88c0-4a01-978a-ead3f5770644",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7bd52e-fde4-46c9-b77c-00e058458d43",
   "metadata": {},
   "source": [
    "Bag of Words menyederhanakan representasi text sebagai sekumpulan kata serta mengabaikan grammar dan posisi tiap kata pada kalimat. Text akan dikonversi menjadi lowercase dan tanda baca akan diabaikan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88b8307-3767-440c-be29-8407fae4d278",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2116a086-4f99-4d1f-8130-8883aaf51ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Linux has been around since the mid-1990s.',\n",
       " 'Linux distributions include the Linux kernel.',\n",
       " 'Linux is one of the most prominent open-source software.']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "    'Linux has been around since the mid-1990s.',\n",
    "    'Linux distributions include the Linux kernel.',\n",
    "    'Linux is one of the most prominent open-source software.'\n",
    "]\n",
    "\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7142aa4f-fa05-4af1-a4b2-585774d59073",
   "metadata": {},
   "source": [
    "### Bag of Words model dengan CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b860c71c-d4fa-4d9b-a70e-5639670ede7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorized_X = vectorizer.fit_transform(corpus).toarray()\n",
    "vectorized_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f391055a-06ba-47f8-9930-eca79963e3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1990s', 'around', 'been', 'distributions', 'has', 'include', 'is',\n",
       "       'kernel', 'linux', 'mid', 'most', 'of', 'one', 'open', 'prominent',\n",
       "       'since', 'software', 'source', 'the'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d245a1b8-a806-4cb9-865e-18f4d30067a0",
   "metadata": {},
   "source": [
    "### Euclidean Distance untuk mengukur jarak antar dokumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e87054b7-34b6-4730-bee3-173cb0b04403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jarak dokumen 1 dan 2: 3.1622776601683795\n",
      "Jarak dokumen 1 dan 3: 3.7416573867739413\n",
      "Jarak dokumen 2 dan 3: 3.4641016151377544\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "distances = euclidean_distances(vectorized_X)\n",
    "\n",
    "for i in range(len(distances)):\n",
    "    for j in range(i, len(distances)):\n",
    "        if i == j:\n",
    "            continue\n",
    "        jarak = distances[i][j]\n",
    "        print(f'Jarak dokumen {i+1} dan {j+1}: {jarak}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c711611a-164c-4cc1-86c0-0b68f2bd2937",
   "metadata": {},
   "source": [
    "## Stop Word Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4a48ec6f-57a3-4d0d-bf6e-b3d6d278fea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Linux has been around since the mid-1990s.',\n",
       " 'Linux distributions include the Linux kernel.',\n",
       " 'Linux is one of the most prominent open-source software.']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04ae351-5d33-404f-8eea-cbcddcc2db2c",
   "metadata": {},
   "source": [
    "### Stop Word Filtering dengan CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8c849012-ae5f-43c9-9304-ea415021e96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 1, 1, 2, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "vectorized_X = vectorizer.fit_transform(corpus).todense()\n",
    "vectorized_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "20732e4d-47c2-48ac-b809-f7e5c675b5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1990s', 'distributions', 'include', 'kernel', 'linux', 'mid',\n",
       "       'open', 'prominent', 'software', 'source'], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a93e63-faad-4541-ab9e-3c46fd297579",
   "metadata": {},
   "source": [
    "## TF-IDF (Term Frequency - Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06b1df1-2836-451e-be9c-9c987796741b",
   "metadata": {},
   "source": [
    "TF-IDF (Term Frequency - Inverse Document Frequency) merupakan salah satu metode statistik yang digunakan untuk mengukur seberapa penting suatu kata terhadap suatu dokumen tertentu dari sekumpulan dokumen atau corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5e43a9bd-d930-4ea8-a0f7-9c1cc6677070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the house had a tiny little mouse',\n",
       " 'the cat saw the mouse',\n",
       " 'the mouse ran away from the house',\n",
       " 'the cat finally ate the mouse',\n",
       " 'the end of the mouse story']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "    'the house had a tiny little mouse', \n",
    "    'the cat saw the mouse',\n",
    "    'the mouse ran away from the house', \n",
    "    'the cat finally ate the mouse',\n",
    "    'the end of the mouse story'\n",
    "]\n",
    "\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f13e824-0402-48fa-afe7-38f0c70a3734",
   "metadata": {},
   "source": [
    "### TF-IDF Weights dengan TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "831ff13f-43dd-4ee7-a12b-7cc9900638cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7)\t0.2808823162882302\n",
      "  (0, 6)\t0.5894630806320427\n",
      "  (0, 11)\t0.5894630806320427\n",
      "  (0, 5)\t0.47557510189256375\n",
      "  (1, 9)\t0.7297183669435993\n",
      "  (1, 2)\t0.5887321837696324\n",
      "  (1, 7)\t0.3477147117091919\n",
      "  (2, 1)\t0.5894630806320427\n",
      "  (2, 8)\t0.5894630806320427\n",
      "  (2, 7)\t0.2808823162882302\n",
      "  (2, 5)\t0.47557510189256375\n",
      "  (3, 0)\t0.5894630806320427\n",
      "  (3, 4)\t0.5894630806320427\n",
      "  (3, 2)\t0.47557510189256375\n",
      "  (3, 7)\t0.2808823162882302\n",
      "  (4, 10)\t0.6700917930430479\n",
      "  (4, 3)\t0.6700917930430479\n",
      "  (4, 7)\t0.3193023297639811\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "response = vectorizer.fit_transform(corpus)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb152c41-c083-481c-b476-523adb14468d",
   "metadata": {},
   "source": [
    "- Kolom pertama merupakan index dari kumpulan kata atau corpus.\n",
    "- Kolom kedua merupakan index dari feature names yang dihasilkan dari bag of words.\n",
    "- Kolom ketiga merupakan bobot dari setiap hasil yang dilakukan TfidfVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b13d6ab6-8063-4121-a4a4-c5fecfc761f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ate', 'away', 'cat', 'end', 'finally', 'house', 'little', 'mouse',\n",
       "       'ran', 'saw', 'story', 'tiny'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "61be7bbc-9caf-42bb-ae8c-9851cfbde31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4755751 , 0.58946308, 0.28088232, 0.        , 0.        ,\n",
       "         0.        , 0.58946308],\n",
       "        [0.        , 0.        , 0.58873218, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.34771471, 0.        , 0.72971837,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.58946308, 0.        , 0.        , 0.        ,\n",
       "         0.4755751 , 0.        , 0.28088232, 0.58946308, 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.58946308, 0.        , 0.4755751 , 0.        , 0.58946308,\n",
       "         0.        , 0.        , 0.28088232, 0.        , 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.67009179, 0.        ,\n",
       "         0.        , 0.        , 0.31930233, 0.        , 0.        ,\n",
       "         0.67009179, 0.        ]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e56dcf76-50d1-4d3f-9531-d4e873491fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ate</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.589463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>away</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.589463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.588732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475575</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.670092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finally</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.589463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <td>0.475575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>0.589463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mouse</th>\n",
       "      <td>0.280882</td>\n",
       "      <td>0.347715</td>\n",
       "      <td>0.280882</td>\n",
       "      <td>0.280882</td>\n",
       "      <td>0.319302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ran</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.589463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saw</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.729718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>story</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.670092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiny</th>\n",
       "      <td>0.589463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               D1        D2        D3        D4        D5\n",
       "ate      0.000000  0.000000  0.000000  0.589463  0.000000\n",
       "away     0.000000  0.000000  0.589463  0.000000  0.000000\n",
       "cat      0.000000  0.588732  0.000000  0.475575  0.000000\n",
       "end      0.000000  0.000000  0.000000  0.000000  0.670092\n",
       "finally  0.000000  0.000000  0.000000  0.589463  0.000000\n",
       "house    0.475575  0.000000  0.475575  0.000000  0.000000\n",
       "little   0.589463  0.000000  0.000000  0.000000  0.000000\n",
       "mouse    0.280882  0.347715  0.280882  0.280882  0.319302\n",
       "ran      0.000000  0.000000  0.589463  0.000000  0.000000\n",
       "saw      0.000000  0.729718  0.000000  0.000000  0.000000\n",
       "story    0.000000  0.000000  0.000000  0.000000  0.670092\n",
       "tiny     0.589463  0.000000  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(response.todense().T, # T adalah transpose\n",
    "                 index=vectorizer.get_feature_names_out(),\n",
    "                 columns=[f'D{i+1}' for i in range(len(corpus))])\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
